# crawler321-preview v0.1.0

**crawler321 é¢„è§ˆç‰ˆ ä¸€å®šç¨‹åº¦ä¸Šç®€åŒ–äº†çˆ¬è™«è¿‡ç¨‹ï¼Œå¼•å…¥ç²¾ç»†åŒ–çš„é¡µé¢å†…å®¹æå–ç­–ç•¥å’Œä¸ªæ€§åŒ–è‡ªå®šä¹‰æå–ç­–ç•¥ï¼ŒåŒæ—¶å¼•å…¥å¤§è¯­è¨€æ¨¡å‹ï¼Œè®©ç½‘é¡µä¿¡æ¯è·å–æ›´åŠ æ–¹ä¾¿ä¾¿æ·ï¼Œå¸Œæœ›é€šè¿‡åƒæ•°æ•°"1,2,3"ä¸€æ ·å³å¯è·å–ä½ æƒ³è¦çš„ä¿¡æ¯**

> **æç¤º**ï¼šè¯¥é¡¹ç›®ç›®å‰å¤„äºå»ºè®¾æµ‹è¯•é˜¶æ®µï¼Œå› æŸäº›åŸå› æš‚ä¸èƒ½å…¬å¼€å®Œæ•´æºç ï¼Œè¿˜æœ›è§è°…ï¼ä½†æä¾›windowså’Œlinuxç¯å¢ƒä¸‹çš„ä½¿ç”¨ï¼Œç›®å‰å…¬å¼€çš„é¡¹ç›®å®Œå…¨å…è´¹è‡ªç”±ä½¿ç”¨ï¼Œè¯¦è§"å®‰è£…ä½¿ç”¨"éƒ¨åˆ†ã€‚

## ğŸ’ åŠŸèƒ½å’Œç‰¹æ€§

* **âœï¸æ”¯æŒç²¾ç»†åŒ–å’Œä¸ªæ€§åŒ–çš„æå–ç­–ç•¥ï¼Œæ»¡è¶³ä¸°å¯Œå¤šæ ·çš„åœºæ™¯éœ€æ±‚ï¼šå¦‚ç»“æ„åŒ–æ•°æ®ã€ç›®å½•å‹ã€å†…å®¹å‹ç­‰**
* **ğŸ¯ç®€å•è€Œé«˜æ•ˆçš„æ“ä½œï¼Œèƒ½å¤Ÿè‡ªåŠ¨è¯†åˆ«å„ç§å„æ ·çš„ç½‘é¡µç±»å‹ï¼Œç”šè‡³ä¸ç”¨è‡ªå·±æŒ‡å®šç­–ç•¥ï¼**
* **ğŸ—’ï¸çµæ´»ç¨³å®šçš„ç»“æœè¾“å‡ºï¼šè‡ªåŠ¨æå–ç½‘é¡µå…ƒæ•°æ®ï¼Œä»¥jsonç¼©è¿›å½¢å¼è¾“å‡º**
* **âš’ï¸å‹å¥½çš„ç”¨æˆ·äº¤äº’æ–¹å¼ï¼šç®€å•çš„å‘½ä»¤è®©æœºå™¨åƒäººä¸€èˆ¬æ“æ§ç½‘é¡µï¼Œå¦‚ç‚¹å‡»ã€è¾“å…¥ã€åˆ·æ–°ç­‰æ“ä½œ**
* **ğŸ‘¼è§¦æ‰‹å¯åŠçš„äººå·¥æ™ºèƒ½ï¼šå¼•å…¥å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸€å¥è¯å°±è½»æ¾è·å–è‡ªå·±æœ€æƒ³è¦çš„å†…å®¹**
* **ğŸª„å¼ºå¤§çš„æ•°æ®å¤‡ä»½æœºåˆ¶ï¼šå¯æä¾›æ•°æ®æœ¬åœ°å­˜å‚¨æœºåˆ¶ï¼Œå³ä½¿å‘ç”Ÿä¸­æ–­ä¹Ÿèƒ½å¿«é€Ÿè·å–å†å²æ•°æ®**
* **ğŸ“Šä¸°å¯Œå……å®çš„æ•°æ®æŠ¥å‘Šï¼šè®©ä½ å¿«é€Ÿå®šä½æœªæˆåŠŸçš„è¯·æ±‚ï¼Œå¤šæ ·åŒ–çš„ç»Ÿè®¡æ•°æ®åˆ†ææ•´ä¸ªcrawlè¿‡ç¨‹**
* **ğŸ“Œä¸€é”®ä½¿ç”¨çš„ä»£ç†ç­–ç•¥ï¼šèƒ½è®©ä½ è¿…é€Ÿæ‘†è„±åŒä¸€æœºå™¨è¯·æ±‚æ¬¡æ•°è¿‡å¤šçš„é—®é¢˜**

## ğŸ”§ å®‰è£…ä½¿ç”¨

åŸºæœ¬è¦æ±‚ï¼špython >= 3.8ï¼Œå‚è€ƒå®‰è£…æ•™ç¨‹ä¸­ä½¿ç”¨venvåˆ›å»ºè™šæ‹Ÿæ•™ç¨‹ï¼Œä¹Ÿå»ºè®®ä½¿ç”¨æ­¤æ–¹å¼ã€‚

```powershell
# å…‹éš†é¡¹ç›®
git clone https://github.com/LeoMooreCST/crawler321-preview.git
```

giteeè¯·æŸ¥çœ‹ï¼š[LeoMooreCST/crawler321-preview ](https://gitee.com/LeoMooreCST/crawler321-preview.git)

### 1. Windowsç¯å¢ƒ

æˆ‘ä»¬ç®€åŒ–äº†å®‰è£…è¿‡ç¨‹

- **ç¬¬ä¸€æ­¥**ï¼šè¿›å…¥crawler321-preview/windowsæ–‡ä»¶å¤¹ã€‚åœ¨powershellç»ˆç«¯ä¸­(ä¸æ˜¯cmd)ï¼Œæ‰§è¡Œï¼š

```powershell
.\install.ps1
```

    **æˆ–è€…**åœ¨cmdä¸­**ä¾æ¬¡æ‰§è¡Œ**ä»¥ä¸‹å‘½ä»¤ï¼š

```powershell
python -m venv ./
.\Scripts\activate
mv .\crawler321\ .\Lib\site-packages\
mv .\crawler321-0.1.0.dist-info\ .\Lib\site-packages\
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/  
pip install --upgrade spark_ai_python -i https://pypi.tuna.tsinghua.edu.cn/simple/
```

> è¯¥è¿‡ç¨‹å¤§çº¦7-15åˆ†é’Ÿå·¦å³ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚
>
> æ­¤è¿‡ç¨‹è‹¥å‡ºç°ä»¥ä¸‹é”™è¯¯ï¼Œå¯å¿½ç•¥ã€‚

```powershell
ERROR: opentelemetry-proto 1.26.0 has requirement protobuf<5.0,>=3.19, but you'll have protobuf 5.27.3 which is incompatible.
ERROR: opentelemetry-api 1.26.0 has requirement importlib-metadata<=8.0.0,>=6.0, but you'll have importlib-metadata 8.2.0 which is incompatible.
ERROR: llama-index-core 0.10.59 has requirement tenacity!=8.4.0,<9.0.0,>=8.2.0, but you'll have tenacity 9.0.0 which is incompatible.  
ERROR: llama-index-legacy 0.9.48 has requirement tenacity<9.0.0,>=8.2.0, but you'll have tenacity 9.0.0 which is incompatible.
```

- **ç¬¬äºŒæ­¥**ï¼š
  - å¦‚æœä¸»æœºä¸Šå·²ç»æœ‰äº†chromeæµè§ˆå™¨, ä½†æœªchromedriverï¼Œåœ¨[Chrome for Testing availability (googlechromelabs.github.io)](https://googlechromelabs.github.io/chrome-for-testing/)ä¸‹è½½å¯¹åº”ç‰ˆæœ¬(åœ¨chromeæµè§ˆå™¨æŸ¥çœ‹ç‰ˆæœ¬ï¼Œè‹¥ä¸æ˜¯æœ€æ–°çš„æ›´æ–°å³å¯)çš„chromedriverï¼Œå°†chromedriveræ·»åŠ åˆ°ç¯å¢ƒå˜é‡å³å¯
    **æ³¨**ï¼šæœ¬åœ°çš„chromeå¯èƒ½ä¼šè‡ªåŠ¨æ›´æ–°ï¼Œå¯¼è‡´chromedriveréœ€è¦é¢‘ç¹æ›´æ–°ï¼Œä¸€ç§è§£å†³æ–¹æ³•å°±æ˜¯å…³é—­chromeçš„è‡ªåŠ¨æ›´æ–°
  - å¦‚æœä¸»æœºæ²¡æœ‰chromeæµè§ˆå™¨ï¼Œåœ¨[Chrome for Testing availability (googlechromelabs.github.io)](https://googlechromelabs.github.io/chrome-for-testing/)ä¸‹è½½chromeå’Œchromdriverè§£å‹åæ–‡ä»¶å¤¹ä¸º:  E:\chrome-win64 (ç›´æ¥åŒ…å«chrome.exe), E:\chromedriver-win64(ç›´æ¥åŒ…å«chromedriver.exe), win11ä¸­ï¼šè®¾ç½® -> ç³»ç»Ÿ -> é«˜çº§ç³»ç»Ÿè®¾ç½® -> ç¯å¢ƒå˜é‡ -> ç³»ç»Ÿå˜é‡(S) -> Path æ·»åŠ å³å¯
  - å¦‚æœä½ ä¸çŸ¥é“å¦‚ä½•æ·»åŠ ç¯å¢ƒå˜é‡ï¼Œå°†ä¸‹è½½çš„zipæ”¾åœ¨æ­¤æ–‡ä»¶å¤¹ï¼Œåœ¨powershellä¸­æ‰§è¡Œå¦‚ä¸‹ï¼ˆè¿‡ç¨‹éœ€è¦ç®¡ç†å‘˜æƒé™ï¼Œå¤šæ¬¡ç‚¹å‡»ç¡®è®¤å³å¯ï¼‰å³å¯ï¼š
    ```powershell
    .\chrome.ps1
    ```

> å¦‚æœä¸Šè¿°è¿‡ç¨‹æœªæŠ¥é”™ï¼Œå³ç¯å¢ƒå®‰è£…æˆåŠŸï¼Œå¯å¯¹ç¯å¢ƒè¿›è¡Œæµ‹è¯•

### 2. linux(æ¨èWSL)

è¿›å…¥crawler321-preview/linuxæ–‡ä»¶å¤¹ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤å³å¯ï¼š

```bash
source install.bash
```

> è¯¥è¿‡ç¨‹å¤§çº¦7-15åˆ†é’Ÿå·¦å³ï¼Œè¯·è€å¿ƒç­‰å¾…
>
> å¦‚æœä¸Šè¿°è¿‡ç¨‹æœªæŠ¥é”™ï¼Œå³ç¯å¢ƒå®‰è£…æˆåŠŸ

**æ³¨ï¼šä»¥ä¸Šå‡åœ¨pythonè™šæ‹Ÿç¯å¢ƒä¸‹è¿›è¡Œï¼Œä¼šè‡ªåŠ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼Œæ— éœ€æ‰‹åŠ¨åˆ›å»ºã€‚ç¼–è¯‘å™¨å¯¹è¯¥é¡¹ç›®åŒ…ä¸­å¯¼å…¥åº“çš„ä½¿ç”¨å‡ºç°çš„æŠ¥é”™ç°è±¡å‡ä¸ºæ­£å¸¸ï¼Œå¯å¿½ç•¥æ‰**ã€‚

### 3. ç¯å¢ƒæµ‹è¯•

ä¾æ¬¡æ‰§è¡Œä»¥ä¸‹pythonæµ‹è¯•ç”¨ä¾‹ï¼š

```python
# test01
from crawler321.run_crawler import RunCrawler
crawler = RunCrawler()
res = crawler.run(url="http://society.people.com.cn/GB/86800/index.html", encoding="GB2312")
print(res)
```

```python
# test02
from crawler321.run_crawler import RunCrawler
crawler = RunCrawler()
res = crawler.run(url="http://society.people.com.cn/n1/2024/0802/c1008-40291310.html", encoding="GB2312")
print(res)
```

```python
# test03
'''
    æ³¨: é¦–æ¬¡å¯åŠ¨è¯¥ç”¨ä¾‹ç­‰å¾…æ—¶é—´æ¯”è¾ƒé•¿, è‹¥å‡ºç°ä»¥ä¸‹æ—¥å¿—, è¯·è€å¿ƒç­‰å¾…ã€‚è¿‡åå¯åŠ¨åˆ™ä¸éœ€è¦åŠ è½½é‚£ä¹ˆé•¿æ—¶é—´
	print("[Logger]ğŸ Lauching LocalSeleniumCrawlerStrategy....")
'''
from crawler321.run_crawler import RunCrawler
from crawler321.extraction_strategy import *
crawler = RunCrawler()
extraction_strategy=XPathExtractionStrategy(
        keys=["ä¹¦å", "å‡ºç‰ˆç¤¾"],
        words=["é£Ÿå—ä¹‹å¾’", "æ¹–å—æ–‡è‰ºå‡ºç‰ˆç¤¾"]
    )
res = crawler.run(
    url="https://book.douban.com/tag/%E5%B0%8F%E8%AF%B4",
    extraction_strategy=extraction_strategy
)
print(res)
```

> æ³¨ï¼šä»¥ä¸Šæµ‹è¯•ç”¨ä¾‹æ‰€æ¶‰åŠç½‘å€å‡ä¸ºå­¦ä¹ ä½¿ç”¨ï¼Œæ— ä»»ä½•å…¶ä»–ç”¨é€”ï¼Œä¾µåˆ ã€‚

è‹¥ä»¥ä¸Šç”¨ä¾‹å‡èƒ½æœ‰æ­£å¸¸å†…å®¹è¾“å‡ºï¼Œåˆ™æ­å–œä½ åŸºæœ¬ç¯å¢ƒå®‰è£…æˆåŠŸï¼Œè§£ææ¥å¼€å¯ä½ çš„æ¢ç´¢ä¹‹æ—…å§ï¼

## âœ¨ å¿«é€Ÿå…¥æ‰‹

### ç¤ºä¾‹1ï¼šä»€ä¹ˆä¹Ÿä¸ç”¨åš

```
import json
from crawler321.run_crawler import RunCrawler
crawler = RunCrawler()
result = crawler.run(url="https://www.demo.com")
result = json.loads(result)
print(result["res"])
```

### ç¤ºä¾‹2ï¼šåªæƒ³æå–ç»“æ„åŒ–æ•°æ®

```
import json
from crawler321.extraction_strategy import ObjectExtractionStrategy
from crawler321.run_crawler import RunCrawler
crawler = RunCrawler()
extraction_strategy = ObjectExtractionStrategy(objects=["å§“å","é‚®ç®±"]) # åªè¿”å›"å§“å"å’Œ"é‚®ç®±"
result = crawler.run(
 Â  Â url="https://www.demo.com",
 Â  Â extraction_strategy=extraction_strategy
)
result = json.loads(result)
print(result["res"])
```

### ç¤ºä¾‹3ï¼šè®©æœºå™¨åƒäººä¸€æ ·æ“ä½œ

```
from crawler321.crawler_strategy import SeleniumCrawlerStrategy
from crawler321.run_crawler import RunCrawler
from crawler321.action import By, Do, SeleniumAction
crawler = RunCrawler(
 Â  Â crawler_strategy=SeleniumCrawlerStrategy()
)
actions = [
 Â  Â SeleniumAction(action=Do.INPUT, target={By.KEY_WORD: "è¯·è¾“å…¥è´¦å·"}, content="123456", wait=2)
 Â  Â SeleniumAction(action=Do.REFRESH)
]
crawler.run(
 Â  Â url="https://www.page1.com",
 Â  Â actions=actions
)

```

## ğŸ“– ä½¿ç”¨æ‰‹å†Œ

æ›´å¤šåŠŸèƒ½å’Œç‰¹æ€§è¯·å…³æ³¨ä½¿ç”¨æ‰‹å†Œï¼š[crawler321ä½¿ç”¨æ‰‹å†Œ](https://kdocs.cn/l/cdvZUdxSmJwe "æ­£åœ¨å¥å…¨å’Œå®Œå–„ä¸­")

## ğŸ“§ è”ç³»æ–¹å¼

- â” å¥ˆä½•ä¸€äººèƒ½åŠ›æ°´å¹³æœ‰é™ï¼Œè‹¥åœ¨å®‰è£…å’Œä½¿ç”¨è¿‡ç¨‹é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œå¯åœ¨ä»“åº“è¯„è®ºåŒºç•™è¨€ï¼Œä½œè€…å°†å°½åŠ›è§£ç­”ã€‚
- âœï¸ å› å¤„äºé¢„è§ˆç‰ˆï¼Œå¾ˆå¤šåŠŸèƒ½å’Œæ–‡æ¡£å¯èƒ½è¿˜ä¸å¤Ÿå®Œå–„å’Œæˆç†Ÿï¼Œè‹¥æœ‰æ›´å¥½çš„å»ºè®®æˆ–è€…æ„è§ï¼Œå¯è”ç³»ä½œè€…é‚®ç®±ï¼šprincekinqiang@163.comï¼Œäº®ç‚¹éƒ¨åˆ†è¢«é‡‡çº³çš„è¯ä½œè€…æœ‰å°å¥–åŠ±å“¦ï¼
- ğŸ§ ç”±äºè¯¥å·¥å…·å¤„äºèµ·æ­¥é˜¶æ®µï¼Œä¸€ä¸ªäººçš„æ™ºæ…§æ˜¯æœ‰é™çš„ï¼Œä¸€ç¾¤äººçš„åŠ›é‡æ‰æ˜¯å¼ºå¤§çš„ã€‚ä½œè€…zçœŸè¯šå¸Œæœ›èƒ½é‡åˆ°æ›´å¤šä¼˜ç§€çš„çˆ±å¥½è€…ä»¬åŠ å…¥åˆ°æ­¤å·¥å…·çš„å¼€å‘å’Œå®Œå–„ä¹‹ä¸­ï¼Œæœ‰æ„è€…å¯è”ç³»é‚®ç®±ï¼šprincekinqiang@163.com (å¤‡æ³¨æ¥æ„)

## Acknowledgements è‡´è°¢

- This project incorporates design elements and concepts from [crawl4ai](https://github.com/unclecode/crawl4ai?tab=readme-ov-file) by unclecode, which is licensed under the Apache License 2.0. We thank the original authors for their contribution to the open-source community. The design and structure provided valuable guidance for this project. We declare that the implements and contents were done on our own. Note that this project is licensed under AGPLv3.
- æˆ‘ä»¬éå¸¸æ„Ÿè°¢[æ˜Ÿç«Sparkå¤§æ¨¡å‹](https://xinghuo.xfyun.cn/sparkapi)æä¾›çš„APIï¼Œåœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­æœ‰æ‰€å¼•ç”¨ï¼Œè¯¦è§ä½¿ç”¨æ‰‹å†Œï¼Œè‹¥æœ‰ä¾µæƒï¼Œè”ç³»å³åˆ ã€ä»…ä½œå­¦ä¹ ä½¿ç”¨ï¼Œæ— ä»»ä½•å…¶ä»–ç”¨é€”ã€‘
- æˆ‘ä»¬éå¸¸æ„Ÿè°¢[å·¨é‡](https://www.juliangip.com/)ã€[æå…‰](https://www.jghttp.com/)å’Œ[å“æ˜“](https://http.py.cn/)(æ’åä¸åˆ†å…ˆå)æä¾›çš„æ¥å£æœåŠ¡ï¼Œåœ¨æˆ‘ä»¬çš„é¡¹ç›®ä¸­æœ‰æ‰€å¼•ç”¨ï¼Œè¯¦è§ä½¿ç”¨æ‰‹å†Œï¼Œè‹¥æœ‰ä¾µæƒï¼Œè”ç³»å³åˆ ã€ä»…ä½œå­¦ä¹ ä½¿ç”¨ï¼Œæ— ä»»ä½•å…¶ä»–ç”¨é€”ã€‘

> æ³¨ï¼šè¯¥å·¥å…·ä¸æä¾›ä»»ä½•ä¸åˆæ³•åŠŸèƒ½ï¼Œä»…ç”¨ä½œå­¦ä¹ ä½¿ç”¨ï¼Œè¯·å¤§å®¶è‡ªè§‰åˆç†åˆæ³•ä½¿ç”¨ï¼
>
> å–œæ¬¢çš„å¯ä»¥ç»™ä½œè€…ç‚¹ä¸ªå°â­â­ï¼
